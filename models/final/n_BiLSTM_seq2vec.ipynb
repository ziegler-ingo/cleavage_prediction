{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CKH0qtixaNo3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CKH0qtixaNo3",
    "outputId": "395abda0-2c29-4d54-d528-8e349cf9903a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install bio-embeddings[seqvec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FXDMuR9Oe2ay",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FXDMuR9Oe2ay",
    "outputId": "8e4f1100-b1c0-42e2-ab1d-4a13e5ac2f6f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded39806-fc83-4b0c-b9ce-14e896a4675f",
   "metadata": {
    "id": "ded39806-fc83-4b0c-b9ce-14e896a4675f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.parametrizations import spectral_norm\n",
    "\n",
    "from allennlp.commands.elmo import ElmoEmbedder\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbbe232-2c39-49c6-9187-a80c6812d813",
   "metadata": {
    "id": "2bbbe232-2c39-49c6-9187-a80c6812d813"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e449b96d-6e11-4b72-a5e6-8f20c1b71115",
   "metadata": {
    "id": "e449b96d-6e11-4b72-a5e6-8f20c1b71115"
   },
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    with open(path, 'r') as csvfile:\n",
    "        train_data = list(csv.reader(csvfile))[1:] # skip col name\n",
    "        sents, lbls = [], []\n",
    "        for s, l in train_data:\n",
    "            sents.append(s)\n",
    "            lbls.append(l)\n",
    "    return sents, lbls\n",
    "\n",
    "# number of trainable parameters in model\n",
    "def get_total_model_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343081b5-03e1-493c-a1b5-405edc1288b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu(x):\n",
    "    \"\"\"\n",
    "    Facebook Research implementation of the gelu activation function.\n",
    "    \n",
    "    For information: OpenAI GPT's gelu is slightly different\n",
    "    (and gives slightly different results):\n",
    "    0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "    \"\"\"\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ffe646-fe1e-4c17-b3e5-c36ed03e81a8",
   "metadata": {
    "id": "e9ffe646-fe1e-4c17-b3e5-c36ed03e81a8"
   },
   "outputs": [],
   "source": [
    "class CleavageDataset(Dataset):\n",
    "    def __init__(self, seq, lbl):\n",
    "        self.seq = seq\n",
    "        self.lbl = lbl\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.seq[idx], self.lbl[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lbl)    \n",
    "    \n",
    "def collate_batch(batch):\n",
    "    ordered_batch = list(zip(*batch))\n",
    "    seq = [list(s) for s in ordered_batch[0]] # is still a string\n",
    "    lbl = torch.tensor([int(l) for l in ordered_batch[1]], dtype=torch.float)\n",
    "    return seq, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cc48e7-1186-4391-b9d8-924eee98b72c",
   "metadata": {
    "id": "b4cc48e7-1186-4391-b9d8-924eee98b72c"
   },
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, embedding_dim, rnn_size, hidden_size, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=rnn_size,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        \n",
    "        self.fc1 = spectral_norm(nn.Linear(rnn_size * 2, hidden_size))\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        # input is already embedded by ELMo\n",
    "        # input shape: (batch_size, seq_len=10, embedding_dim)\n",
    "        embedded = self.dropout(seq)\n",
    "\n",
    "        # input shape: (batch_size, seq_len, embedding_dim)\n",
    "        out, _ = self.lstm(embedded)\n",
    "        \n",
    "        # input shape: (batch_size, seq_len, 2*hidden_size)\n",
    "        pooled, _ = torch.max(out, dim=1)\n",
    "        \n",
    "        # input shape: (batch_size, 2*hidden_size)\n",
    "        out = self.dropout(gelu(self.fc1(pooled)))\n",
    "        \n",
    "        # input shape: (batch_size, hidden_size)\n",
    "        # output shape: (batch_size)\n",
    "        out = self.fc2(out).squeeze()\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e91040-ea43-4a0f-b17a-bcbb2b38ac99",
   "metadata": {
    "id": "a0e91040-ea43-4a0f-b17a-bcbb2b38ac99"
   },
   "outputs": [],
   "source": [
    "def process(model, loader, criterion, optim=None):\n",
    "    epoch_loss, num_correct, total = 0, 0, 0\n",
    "    preds, lbls = [], []\n",
    "    \n",
    "    for seq, lbl in tqdm(\n",
    "        loader,\n",
    "        desc=\"Train: \" if optim is not None else \"Eval: \",\n",
    "        file=sys.stdout,\n",
    "        unit=\"batches\"\n",
    "    ):\n",
    "        seq, _ = embedder.batch_to_embeddings(seq) # is already on GPU\n",
    "        seq = seq.sum(dim=1)\n",
    "        lbl = lbl.to(device)\n",
    "        \n",
    "        scores = model(seq)\n",
    "        loss = criterion(scores, lbl)\n",
    "        \n",
    "        if optim is not None:\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        num_correct += ((scores > 0) == lbl).sum().item()\n",
    "        total += len(seq)\n",
    "        preds.extend(scores.detach().tolist())\n",
    "        lbls.extend(lbl.detach().tolist())\n",
    "    return epoch_loss / total, num_correct / total, roc_auc_score(lbls, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z8KrBUMem0CO",
   "metadata": {
    "id": "z8KrBUMem0CO"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "embedder = ElmoEmbedder(\n",
    "    options_file='./drive/MyDrive/data/seqvec/options.json',\n",
    "    weight_file='./drive/MyDrive/data/seqvec/weights.hdf5',\n",
    "    cuda_device=0 # use colab gpu\n",
    ")\n",
    "\n",
    "# load train and dev data\n",
    "train_seqs, train_lbl = read_data('./drive/MyDrive/data/n_train.csv')\n",
    "dev_seqs, dev_lbl = read_data('./drive/MyDrive/data/n_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff5c30b-2822-4871-8ab5-0ec37673f1f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fff5c30b-2822-4871-8ab5-0ec37673f1f8",
    "outputId": "089718d3-f10f-46a3-e5a8-cdcaa2273298"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 25\n",
    "BATCH_SIZE = 512\n",
    "EMBEDDING_DIM = 1024 # given by ELMo\n",
    "RNN_SIZE = 512\n",
    "HIDDEN_SIZE = 128\n",
    "DROPOUT = 0.5\n",
    "LEARNING_RATE = 5e-5\n",
    "\n",
    "model = BiLSTM(\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    rnn_size=RNN_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    dropout=DROPOUT\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# create train and dev loader\n",
    "train_data = CleavageDataset(train_seqs, train_lbl)\n",
    "train_loader = DataLoader(train_data, batch_size = BATCH_SIZE, shuffle=True, collate_fn=collate_batch, num_workers=2)\n",
    "\n",
    "dev_data = CleavageDataset(dev_seqs, dev_lbl)\n",
    "dev_loader = DataLoader(dev_data, batch_size = BATCH_SIZE, shuffle=True, collate_fn=collate_batch, num_workers=2)\n",
    "\n",
    "print(f\"Total trainable model parameters: {get_total_model_params(model):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbe5697-c1a7-4f53-9826-9e91e80d0b18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3fbe5697-c1a7-4f53-9826-9e91e80d0b18",
    "outputId": "649b2f67-4623-4cf3-d3e9-0f8fee24a94c"
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "print(\"Starting Training.\")\n",
    "highest_val_auc = 0\n",
    "train_losses, train_accuracies, train_aucs = [], [], []\n",
    "val_losses, val_accuracies, val_aucs = [], [], []\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    model.train()\n",
    "    train_loss, train_acc, train_auc = process(model, train_loader, criterion, optimizer)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss, val_acc, val_auc = process(model, dev_loader, criterion)\n",
    "        \n",
    "    # save current acc, loss\n",
    "    train_losses.append((epoch, train_loss))\n",
    "    train_accuracies.append((epoch, train_acc))\n",
    "    train_aucs.append((epoch, train_auc))\n",
    "    val_losses.append((epoch, val_loss))\n",
    "    val_accuracies.append((epoch, val_acc))\n",
    "    val_aucs.append((epoch, val_auc))\n",
    "    \n",
    "    if val_auc > highest_val_auc:\n",
    "        highest_val_auc = val_auc\n",
    "        path = f\"./drive/MyDrive/data/n_term/seqvecBiLSTM/auc{val_auc:.4f}_epoch{epoch}.pt\"\n",
    "        torch.save(model.state_dict(), path)\n",
    "        \n",
    "    print(\n",
    "        f\"Training:   [Epoch {epoch:2d}, Loss: {train_loss:8.4f}, Acc: {train_acc:.4f}, AUC: {train_auc:.4f}]\"\n",
    "    )\n",
    "    print(f\"Evaluation: [Epoch {epoch:2d}, Loss: {val_loss:8.4f}, Acc: {val_acc:.4f}, AUC: {val_auc:.4f}]\")\n",
    "    \n",
    "print(\"Finished Training.\")\n",
    "train_time = (time() - start) / 60\n",
    "print(f\"Training took {train_time} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126fd50d-b4b5-4da7-a8e5-8ebeed450b22",
   "metadata": {
    "id": "126fd50d-b4b5-4da7-a8e5-8ebeed450b22"
   },
   "outputs": [],
   "source": [
    "# save training stats\n",
    "lsts = [train_losses, train_accuracies, val_losses, val_accuracies, train_aucs, val_aucs, train_time]\n",
    "names = [\n",
    "    \"train_losses\",\n",
    "    \"train_accuracies\",\n",
    "    \"val_losses\",\n",
    "    \"val_accuracies\",\n",
    "    \"train_aucs\",\n",
    "    \"val_aucs\",\n",
    "    \"train_time\",\n",
    "]\n",
    "to_save = dict()\n",
    "for name, lst in zip(names, lsts):\n",
    "    to_save[name] = lst\n",
    "\n",
    "with open(f\"./drive/MyDrive/data/n_term/seqvecBiLSTM/metrics.pkl\", \"wb\") as f:\n",
    "    pickle.dump(to_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Finished Saving Details.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b9f839-ffcd-4d84-b060-80bb75be99e7",
   "metadata": {
    "id": "08b9f839-ffcd-4d84-b060-80bb75be99e7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "n_term-BiLSTM-seqvec.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
