{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c3670e-2187-42ce-8fda-25a8ba1c80df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDEA: use ProtTrans pipeline as feature extraction (instead of embeddings) and build model on top of it\n",
    "# check whether input format makes sense\n",
    "# https://github.com/agemagician/ProtTrans/blob/master/Embedding/PyTorch/Basic/ProtBert.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded39806-fc83-4b0c-b9ce-14e896a4675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbbe232-2c39-49c6-9187-a80c6812d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f9ce2e-d5b0-4c81-acce-2ed167ab1f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e449b96d-6e11-4b72-a5e6-8f20c1b71115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_data(path):\n",
    "#     with open(path, 'r') as csvfile:\n",
    "#         train_data = list(csv.reader(csvfile))[1:] # skip col name\n",
    "#         sents, lbls = [], []\n",
    "#         for i in range(0, len(train_data), 16):\n",
    "#             s, l = zip(*train_data[i:i+16])\n",
    "#             sents.append(s)\n",
    "#             lbls.append(l)\n",
    "#     return sents, lbls\n",
    "\n",
    "def read_data(path):\n",
    "    with open(path, 'r') as csvfile:\n",
    "        train_data = list(csv.reader(csvfile))[1:] # skip col name\n",
    "        sents, lbls = [], []\n",
    "        for s, l in train_data:\n",
    "            sents.append(s)\n",
    "            lbls.append(l)\n",
    "    return sents, lbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe3cdd7-3b08-40d0-b8ce-e288f7fda7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents, lbl = read_data('../data/n_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd00749-175c-451d-bb03-4cab55cda1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(sents, specials=['<UNK>'])\n",
    "vocab.set_default_index(vocab['<UNK>'])\n",
    "\n",
    "encode_text = lambda x: vocab(list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ffe646-fe1e-4c17-b3e5-c36ed03e81a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleavageDataset(Dataset):\n",
    "    def __init__(self, seq, lbl):\n",
    "        self.seq = seq\n",
    "        self.lbl = lbl\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.seq[idx], self.lbl[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a696c7-9693-46c5-b848-26fa699fa5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleavageBatch:\n",
    "    def __init__(self, batch: List[Tuple[str, str]]):\n",
    "        ordered_batch = list(zip(*batch))\n",
    "        self.seq = torch.tensor([encode_text(seq) for seq in ordered_batch[0]], dtype=torch.int64)\n",
    "        self.lbl = torch.tensor([int(l) for l in ordered_batch[1]], dtype=torch.long)\n",
    "        \n",
    "    def pin_memory(self):\n",
    "        self.seq = self.seq.pin_memory()\n",
    "        self.lbl = self.lbl.pin_memory()\n",
    "        return self\n",
    "    \n",
    "def collate_wrapper(batch):\n",
    "    return CleavageBatch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8a2555-0b10-4dea-a573-5944623e4a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CleavageDataset(sents, lbl)\n",
    "loader = DataLoader(data, batch_size = 8, shuffle=True, collate_fn=collate_wrapper, pin_memory=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2af615-0fc1-4e29-9914-a61bef7fba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in loader:\n",
    "    print(sample.seq)\n",
    "    print(sample.lbl)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cc48e7-1186-4391-b9d8-924eee98b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadBiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_size1, rnn_size2, rnn_size3, rnn_size4, dropout, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=embedding_dim,\n",
    "        )\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=rnn_size1,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.lstm2 = nn.LSTM(\n",
    "            input_size=2*rnn_size1,\n",
    "            hidden_size=rnn_size2,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.lstm3 = nn.LSTM(\n",
    "            input_size=2*rnn_size2,\n",
    "            hidden_size=rnn_size3,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.lstm4 = nn.LSTM(\n",
    "            input_size=2*rnn_size3,\n",
    "            hidden_size=rnn_size4,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(rnn_size4 * 2, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd623fab-4267-413c-814f-f7d0a9d67497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9171b098-7f8f-4fb7-b08a-149aafacae6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
