warmup: 100%|██████████████████████████████████████████████████| 2236/2236 [00:19<00:00, 114.46batches/s]
warmup: 100%|██████████████████████████████████████████████████| 2236/2236 [00:18<00:00, 118.95batches/s]
Warm-Up Model1: [Epoch  1, Loss: -0.000036, Acc: 0.6027, AUC: 0.6161]
Warm-Up Model2: [Epoch  1, Loss: -0.000029, Acc: 0.5936, AUC: 0.6005]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 91.94batches/s]
Evaluation Set: [Epoch  1, Loss: 0.590031, Acc: 0.6800, AUC: 0.7453]
warmup: 100%|██████████████████████████████████████████████████| 2236/2236 [00:19<00:00, 113.72batches/s]
warmup: 100%|██████████████████████████████████████████████████| 2236/2236 [00:18<00:00, 118.85batches/s]
Warm-Up Model1: [Epoch  2, Loss: -0.000096, Acc: 0.6749, AUC: 0.7324]
Warm-Up Model2: [Epoch  2, Loss: -0.000071, Acc: 0.6445, AUC: 0.6962]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 91.40batches/s]
Evaluation Set: [Epoch  2, Loss: 0.574175, Acc: 0.6883, AUC: 0.7595]
warmup: 100%|██████████████████████████████████████████████████| 2236/2236 [00:19<00:00, 112.95batches/s]
warmup: 100%|██████████████████████████████████████████████████| 2236/2236 [00:19<00:00, 115.07batches/s]
Warm-Up Model1: [Epoch  3, Loss: -0.000100, Acc: 0.6785, AUC: 0.7402]
Warm-Up Model2: [Epoch  3, Loss: -0.000080, Acc: 0.6567, AUC: 0.7125]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 91.40batches/s]
Evaluation Set: [Epoch  3, Loss: 0.572023, Acc: 0.6895, AUC: 0.7617]
warmup: 100%|██████████████████████████████████████████████████| 2236/2236 [00:20<00:00, 110.11batches/s]
warmup: 100%|██████████████████████████████████████████████████| 2236/2236 [00:19<00:00, 115.42batches/s]
Warm-Up Model1: [Epoch  4, Loss: -0.000102, Acc: 0.6800, AUC: 0.7432]
Warm-Up Model2: [Epoch  4, Loss: -0.000084, Acc: 0.6610, AUC: 0.7185]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 90.25batches/s]
Evaluation Set: [Epoch  4, Loss: 0.570347, Acc: 0.6905, AUC: 0.7637]
warmup: 100%|██████████████████████████████████████████████████| 2236/2236 [00:20<00:00, 111.79batches/s]
warmup: 100%|██████████████████████████████████████████████████| 2236/2236 [00:19<00:00, 117.63batches/s]
Warm-Up Model1: [Epoch  5, Loss: -0.000103, Acc: 0.6816, AUC: 0.7455]
Warm-Up Model2: [Epoch  5, Loss: -0.000086, Acc: 0.6634, AUC: 0.7225]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 91.96batches/s]
Evaluation Set: [Epoch  5, Loss: 0.567882, Acc: 0.6925, AUC: 0.7642]
warmup: 100%|██████████████████████████████████████████████████| 2236/2236 [00:19<00:00, 112.45batches/s]
warmup: 100%|██████████████████████████████████████████████████| 2236/2236 [00:19<00:00, 112.47batches/s]
Warm-Up Model1: [Epoch  6, Loss: -0.000104, Acc: 0.6819, AUC: 0.7472]
Warm-Up Model2: [Epoch  6, Loss: -0.000088, Acc: 0.6649, AUC: 0.7249]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 92.08batches/s]
Evaluation Set: [Epoch  6, Loss: 0.566567, Acc: 0.6931, AUC: 0.7655]
warmup: 100%|██████████████████████████████████████████████████| 2236/2236 [00:20<00:00, 109.30batches/s]
warmup: 100%|██████████████████████████████████████████████████| 2236/2236 [00:18<00:00, 118.07batches/s]
Warm-Up Model1: [Epoch  7, Loss: -0.000105, Acc: 0.6831, AUC: 0.7483]
Warm-Up Model2: [Epoch  7, Loss: -0.000090, Acc: 0.6665, AUC: 0.7275]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 92.15batches/s]
Evaluation Set: [Epoch  7, Loss: 0.567463, Acc: 0.6934, AUC: 0.7660]
warmup: 100%|██████████████████████████████████████████████████| 2236/2236 [00:19<00:00, 111.93batches/s]
warmup: 100%|██████████████████████████████████████████████████| 2236/2236 [00:19<00:00, 116.70batches/s]
Warm-Up Model1: [Epoch  8, Loss: -0.000106, Acc: 0.6833, AUC: 0.7494]
Warm-Up Model2: [Epoch  8, Loss: -0.000091, Acc: 0.6675, AUC: 0.7289]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 91.86batches/s]
Evaluation Set: [Epoch  8, Loss: 0.566395, Acc: 0.6932, AUC: 0.7665]
warmup: 100%|██████████████████████████████████████████████████| 2236/2236 [00:20<00:00, 110.22batches/s]
warmup: 100%|██████████████████████████████████████████████████| 2236/2236 [00:19<00:00, 117.50batches/s]
Warm-Up Model1: [Epoch  9, Loss: -0.000106, Acc: 0.6835, AUC: 0.7496]
Warm-Up Model2: [Epoch  9, Loss: -0.000092, Acc: 0.6688, AUC: 0.7306]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 91.43batches/s]
Evaluation Set: [Epoch  9, Loss: 0.566626, Acc: 0.6936, AUC: 0.7668]
warmup: 100%|██████████████████████████████████████████████████| 2236/2236 [00:19<00:00, 112.62batches/s]
warmup: 100%|██████████████████████████████████████████████████| 2236/2236 [00:19<00:00, 116.63batches/s]
Warm-Up Model1: [Epoch 10, Loss: -0.000107, Acc: 0.6840, AUC: 0.7506]
Warm-Up Model2: [Epoch 10, Loss: -0.000093, Acc: 0.6703, AUC: 0.7325]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 90.78batches/s]
Evaluation Set: [Epoch 10, Loss: 0.564577, Acc: 0.6951, AUC: 0.7677]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 201.90batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 211.45batches/s]
train model1: 100%|█████████████████████████████████████████████| 8442/8442 [01:32<00:00, 90.94batches/s]
train model2: 100%|███████████████████████████████████████████| 10685/10685 [01:54<00:00, 93.14batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 89.75batches/s]
Training Set: [Epoch 11, Loss1: 0.595513, Loss2: 0.604008]
DivideMix Training: [Epoch 11, Loss1: 0.001129, Loss2: 0.001350]
Evaluation Set: [Epoch 11, Loss: 2.118285, Acc: 0.6863, AUC: 0.7547]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 201.22batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 208.73batches/s]
train model1: 100%|███████████████████████████████████████████| 12344/12344 [02:16<00:00, 90.23batches/s]
train model2: 100%|███████████████████████████████████████████| 12126/12126 [02:11<00:00, 92.32batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 90.32batches/s]
Training Set: [Epoch 12, Loss1: 1.323267, Loss2: 0.992164]
DivideMix Training: [Epoch 12, Loss1: 0.001318, Loss2: 0.001299]
Evaluation Set: [Epoch 12, Loss: 2.455192, Acc: 0.6880, AUC: 0.7432]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 200.42batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 209.86batches/s]
train model1: 100%|███████████████████████████████████████████| 12214/12214 [02:14<00:00, 90.71batches/s]
train model2: 100%|███████████████████████████████████████████| 12343/12343 [02:13<00:00, 92.41batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 89.90batches/s]
Training Set: [Epoch 13, Loss1: 1.341999, Loss2: 1.286170]
DivideMix Training: [Epoch 13, Loss1: 0.001282, Loss2: 0.001313]
Evaluation Set: [Epoch 13, Loss: 2.795598, Acc: 0.6879, AUC: 0.7393]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 202.09batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 209.46batches/s]
train model1: 100%|███████████████████████████████████████████| 12396/12396 [02:15<00:00, 91.47batches/s]
train model2: 100%|███████████████████████████████████████████| 12256/12256 [02:12<00:00, 92.30batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 89.23batches/s]
Training Set: [Epoch 14, Loss1: 1.549562, Loss2: 1.402009]
DivideMix Training: [Epoch 14, Loss1: 0.001294, Loss2: 0.001281]
Evaluation Set: [Epoch 14, Loss: 2.823582, Acc: 0.6878, AUC: 0.7400]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 201.86batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 212.23batches/s]
train model1: 100%|███████████████████████████████████████████| 12254/12254 [02:14<00:00, 90.78batches/s]
train model2: 100%|███████████████████████████████████████████| 12421/12421 [02:16<00:00, 91.29batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 90.66batches/s]
Training Set: [Epoch 15, Loss1: 1.402222, Loss2: 1.601415]
DivideMix Training: [Epoch 15, Loss1: 0.001263, Loss2: 0.001309]
Evaluation Set: [Epoch 15, Loss: 2.869078, Acc: 0.6878, AUC: 0.7357]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 202.40batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 209.88batches/s]
train model1: 100%|███████████████████████████████████████████| 12375/12375 [02:16<00:00, 90.42batches/s]
train model2: 100%|███████████████████████████████████████████| 12294/12294 [02:12<00:00, 92.56batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 90.89batches/s]
Training Set: [Epoch 16, Loss1: 1.551671, Loss2: 1.453227]
DivideMix Training: [Epoch 16, Loss1: 0.001271, Loss2: 0.001276]
Evaluation Set: [Epoch 16, Loss: 3.037484, Acc: 0.6887, AUC: 0.7322]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 201.51batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 210.38batches/s]
train model1: 100%|███████████████████████████████████████████| 12311/12311 [02:14<00:00, 91.58batches/s]
train model2: 100%|███████████████████████████████████████████| 12400/12400 [02:13<00:00, 92.86batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 92.15batches/s]
Training Set: [Epoch 17, Loss1: 1.545878, Loss2: 1.619897]
DivideMix Training: [Epoch 17, Loss1: 0.001247, Loss2: 0.001288]
Evaluation Set: [Epoch 17, Loss: 2.993674, Acc: 0.6882, AUC: 0.7387]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 206.35batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 214.98batches/s]
train model1: 100%|███████████████████████████████████████████| 12415/12415 [02:15<00:00, 91.80batches/s]
train model2: 100%|███████████████████████████████████████████| 12310/12310 [02:12<00:00, 92.65batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 92.57batches/s]
Training Set: [Epoch 18, Loss1: 1.634044, Loss2: 1.506606]
DivideMix Training: [Epoch 18, Loss1: 0.001258, Loss2: 0.001265]
Evaluation Set: [Epoch 18, Loss: 3.265169, Acc: 0.6890, AUC: 0.7339]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 205.48batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 213.87batches/s]
train model1: 100%|███████████████████████████████████████████| 12319/12319 [02:14<00:00, 91.63batches/s]
train model2: 100%|███████████████████████████████████████████| 12444/12444 [02:12<00:00, 94.03batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 92.01batches/s]
Training Set: [Epoch 19, Loss1: 1.744040, Loss2: 1.655241]
DivideMix Training: [Epoch 19, Loss1: 0.001233, Loss2: 0.001278]
Evaluation Set: [Epoch 19, Loss: 3.117120, Acc: 0.6882, AUC: 0.7369]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 206.77batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 214.00batches/s]
train model1: 100%|███████████████████████████████████████████| 12412/12412 [02:14<00:00, 92.12batches/s]
train model2: 100%|███████████████████████████████████████████| 12321/12321 [02:12<00:00, 93.19batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 91.86batches/s]
Training Set: [Epoch 20, Loss1: 1.589450, Loss2: 1.647828]
DivideMix Training: [Epoch 20, Loss1: 0.001231, Loss2: 0.001263]
Evaluation Set: [Epoch 20, Loss: 3.231033, Acc: 0.6886, AUC: 0.7362]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 206.57batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 215.86batches/s]
train model1: 100%|███████████████████████████████████████████| 12348/12348 [02:13<00:00, 92.29batches/s]
train model2: 100%|███████████████████████████████████████████| 12447/12447 [02:14<00:00, 92.40batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 91.85batches/s]
Training Set: [Epoch 21, Loss1: 1.669241, Loss2: 1.681071]
DivideMix Training: [Epoch 21, Loss1: 0.001215, Loss2: 0.001280]
Evaluation Set: [Epoch 21, Loss: 3.209130, Acc: 0.6887, AUC: 0.7334]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 206.37batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 213.51batches/s]
train model1: 100%|███████████████████████████████████████████| 12443/12443 [02:16<00:00, 91.42batches/s]
train model2: 100%|███████████████████████████████████████████| 12361/12361 [02:12<00:00, 93.07batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 91.98batches/s]
Training Set: [Epoch 22, Loss1: 1.644458, Loss2: 1.669791]
DivideMix Training: [Epoch 22, Loss1: 0.001226, Loss2: 0.001268]
Evaluation Set: [Epoch 22, Loss: 3.235330, Acc: 0.6896, AUC: 0.7351]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 205.97batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 213.75batches/s]
train model1: 100%|███████████████████████████████████████████| 12378/12378 [02:13<00:00, 92.39batches/s]
train model2: 100%|███████████████████████████████████████████| 12462/12462 [02:13<00:00, 93.19batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 92.28batches/s]
Training Set: [Epoch 23, Loss1: 1.659119, Loss2: 1.666032]
DivideMix Training: [Epoch 23, Loss1: 0.001216, Loss2: 0.001278]
Evaluation Set: [Epoch 23, Loss: 3.294198, Acc: 0.6897, AUC: 0.7309]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 208.39batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 214.86batches/s]
train model1: 100%|███████████████████████████████████████████| 12434/12434 [02:15<00:00, 91.95batches/s]
train model2: 100%|███████████████████████████████████████████| 12396/12396 [02:13<00:00, 93.14batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 89.54batches/s]
Training Set: [Epoch 24, Loss1: 1.753470, Loss2: 1.637617]
DivideMix Training: [Epoch 24, Loss1: 0.001215, Loss2: 0.001249]
Evaluation Set: [Epoch 24, Loss: 3.396758, Acc: 0.6895, AUC: 0.7323]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 200.47batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 209.43batches/s]
train model1: 100%|███████████████████████████████████████████| 12417/12417 [02:17<00:00, 90.07batches/s]
train model2: 100%|███████████████████████████████████████████| 12511/12511 [02:14<00:00, 93.17batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 89.48batches/s]
Training Set: [Epoch 25, Loss1: 1.727930, Loss2: 1.774944]
DivideMix Training: [Epoch 25, Loss1: 0.001209, Loss2: 0.001285]
Evaluation Set: [Epoch 25, Loss: 3.338281, Acc: 0.6897, AUC: 0.7332]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 201.84batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 209.76batches/s]
train model1: 100%|███████████████████████████████████████████| 12535/12535 [02:20<00:00, 89.36batches/s]
train model2: 100%|███████████████████████████████████████████| 12396/12396 [02:17<00:00, 90.27batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 88.15batches/s]
Training Set: [Epoch 26, Loss1: 1.768121, Loss2: 1.678467]
DivideMix Training: [Epoch 26, Loss1: 0.001234, Loss2: 0.001248]
Evaluation Set: [Epoch 26, Loss: 3.294237, Acc: 0.6893, AUC: 0.7370]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 197.71batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 206.14batches/s]
train model1: 100%|███████████████████████████████████████████| 12443/12443 [02:19<00:00, 88.95batches/s]
train model2: 100%|███████████████████████████████████████████| 12501/12501 [02:18<00:00, 90.30batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 85.37batches/s]
Training Set: [Epoch 27, Loss1: 1.663996, Loss2: 1.723875]
DivideMix Training: [Epoch 27, Loss1: 0.001206, Loss2: 0.001266]
Evaluation Set: [Epoch 27, Loss: 3.244228, Acc: 0.6899, AUC: 0.7311]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 193.89batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 202.12batches/s]
train model1: 100%|███████████████████████████████████████████| 12539/12539 [02:21<00:00, 88.56batches/s]
train model2: 100%|███████████████████████████████████████████| 12418/12418 [02:19<00:00, 89.03batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 85.45batches/s]
Training Set: [Epoch 28, Loss1: 1.642652, Loss2: 1.694987]
DivideMix Training: [Epoch 28, Loss1: 0.001222, Loss2: 0.001244]
Evaluation Set: [Epoch 28, Loss: 3.438891, Acc: 0.6901, AUC: 0.7388]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 192.20batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 200.53batches/s]
train model1: 100%|███████████████████████████████████████████| 12483/12483 [02:22<00:00, 87.42batches/s]
train model2: 100%|███████████████████████████████████████████| 12500/12500 [02:19<00:00, 89.33batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 84.22batches/s]
Training Set: [Epoch 29, Loss1: 1.765628, Loss2: 1.765968]
DivideMix Training: [Epoch 29, Loss1: 0.001210, Loss2: 0.001265]
Evaluation Set: [Epoch 29, Loss: 3.357678, Acc: 0.6904, AUC: 0.7359]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 190.01batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 199.72batches/s]
train model1: 100%|███████████████████████████████████████████| 12510/12510 [02:21<00:00, 88.42batches/s]
train model2: 100%|███████████████████████████████████████████| 12432/12432 [02:18<00:00, 89.71batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 85.53batches/s]
Training Set: [Epoch 30, Loss1: 1.700894, Loss2: 1.749016]
DivideMix Training: [Epoch 30, Loss1: 0.001220, Loss2: 0.001246]
Evaluation Set: [Epoch 30, Loss: 3.343096, Acc: 0.6904, AUC: 0.7330]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 190.93batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 199.35batches/s]
train model1: 100%|███████████████████████████████████████████| 12482/12482 [02:21<00:00, 88.25batches/s]
train model2: 100%|███████████████████████████████████████████| 12562/12562 [02:20<00:00, 89.23batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 84.58batches/s]
Training Set: [Epoch 31, Loss1: 1.738573, Loss2: 1.722221]
DivideMix Training: [Epoch 31, Loss1: 0.001213, Loss2: 0.001272]
Evaluation Set: [Epoch 31, Loss: 3.307831, Acc: 0.6899, AUC: 0.7348]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 189.17batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 198.74batches/s]
train model1: 100%|███████████████████████████████████████████| 12618/12618 [02:22<00:00, 88.60batches/s]
train model2: 100%|███████████████████████████████████████████| 12448/12448 [02:19<00:00, 89.19batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 84.41batches/s]
Training Set: [Epoch 32, Loss1: 1.711690, Loss2: 1.704137]
DivideMix Training: [Epoch 32, Loss1: 0.001224, Loss2: 0.001251]
Evaluation Set: [Epoch 32, Loss: 3.148919, Acc: 0.6900, AUC: 0.7269]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 190.75batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 198.54batches/s]
train model1: 100%|███████████████████████████████████████████| 12489/12489 [02:21<00:00, 88.51batches/s]
train model2: 100%|███████████████████████████████████████████| 12506/12506 [02:19<00:00, 89.78batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 84.72batches/s]
Training Set: [Epoch 33, Loss1: 1.549881, Loss2: 1.713401]
DivideMix Training: [Epoch 33, Loss1: 0.001212, Loss2: 0.001250]
Evaluation Set: [Epoch 33, Loss: 3.365460, Acc: 0.6908, AUC: 0.7372]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 190.24batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 200.56batches/s]
train model1: 100%|███████████████████████████████████████████| 12586/12586 [02:21<00:00, 88.99batches/s]
train model2: 100%|███████████████████████████████████████████| 12453/12453 [02:19<00:00, 89.40batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 84.37batches/s]
Training Set: [Epoch 34, Loss1: 1.737878, Loss2: 1.731319]
DivideMix Training: [Epoch 34, Loss1: 0.001230, Loss2: 0.001250]
Evaluation Set: [Epoch 34, Loss: 3.431361, Acc: 0.6902, AUC: 0.7358]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 190.28batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 198.87batches/s]
train model1: 100%|███████████████████████████████████████████| 12480/12480 [02:21<00:00, 88.11batches/s]
train model2: 100%|███████████████████████████████████████████| 12536/12536 [02:19<00:00, 90.06batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 84.22batches/s]
Training Set: [Epoch 35, Loss1: 1.750366, Loss2: 1.775663]
DivideMix Training: [Epoch 35, Loss1: 0.001211, Loss2: 0.001257]
Evaluation Set: [Epoch 35, Loss: 3.278522, Acc: 0.6903, AUC: 0.7339]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 190.69batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 199.56batches/s]
train model1: 100%|███████████████████████████████████████████| 12564/12564 [02:22<00:00, 87.92batches/s]
train model2: 100%|███████████████████████████████████████████| 12443/12443 [02:19<00:00, 89.48batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 85.17batches/s]
Training Set: [Epoch 36, Loss1: 1.680732, Loss2: 1.697086]
DivideMix Training: [Epoch 36, Loss1: 0.001220, Loss2: 0.001248]
Evaluation Set: [Epoch 36, Loss: 3.288430, Acc: 0.6907, AUC: 0.7305]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 191.17batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 200.07batches/s]
train model1: 100%|███████████████████████████████████████████| 12510/12510 [02:21<00:00, 88.41batches/s]
train model2: 100%|███████████████████████████████████████████| 12558/12558 [02:19<00:00, 89.99batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 84.08batches/s]
Training Set: [Epoch 37, Loss1: 1.651429, Loss2: 1.719263]
DivideMix Training: [Epoch 37, Loss1: 0.001214, Loss2: 0.001262]
Evaluation Set: [Epoch 37, Loss: 3.324276, Acc: 0.6906, AUC: 0.7347]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 190.05batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 198.94batches/s]
train model1: 100%|███████████████████████████████████████████| 12591/12591 [02:19<00:00, 90.09batches/s]
train model2: 100%|███████████████████████████████████████████| 12498/12498 [02:18<00:00, 90.41batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 86.63batches/s]
Training Set: [Epoch 38, Loss1: 1.667673, Loss2: 1.723144]
DivideMix Training: [Epoch 38, Loss1: 0.001216, Loss2: 0.001250]
Evaluation Set: [Epoch 38, Loss: 3.292112, Acc: 0.6903, AUC: 0.7315]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 195.04batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 203.35batches/s]
train model1: 100%|███████████████████████████████████████████| 12535/12535 [02:19<00:00, 90.04batches/s]
train model2: 100%|███████████████████████████████████████████| 12558/12558 [02:18<00:00, 90.49batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 86.26batches/s]
Training Set: [Epoch 39, Loss1: 1.631948, Loss2: 1.718663]
DivideMix Training: [Epoch 39, Loss1: 0.001207, Loss2: 0.001254]
Evaluation Set: [Epoch 39, Loss: 3.433929, Acc: 0.6907, AUC: 0.7389]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 194.50batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 204.10batches/s]
train model1: 100%|███████████████████████████████████████████| 12618/12618 [02:17<00:00, 91.48batches/s]
train model2: 100%|███████████████████████████████████████████| 12503/12503 [02:13<00:00, 93.57batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 91.07batches/s]
Training Set: [Epoch 40, Loss1: 1.744741, Loss2: 1.738202]
DivideMix Training: [Epoch 40, Loss1: 0.001215, Loss2: 0.001242]
Evaluation Set: [Epoch 40, Loss: 3.521146, Acc: 0.6909, AUC: 0.7402]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 205.94batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 215.38batches/s]
train model1: 100%|███████████████████████████████████████████| 12579/12579 [02:15<00:00, 93.07batches/s]
train model2: 100%|███████████████████████████████████████████| 12607/12607 [02:16<00:00, 92.27batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 86.02batches/s]
Training Set: [Epoch 41, Loss1: 1.791242, Loss2: 1.767173]
DivideMix Training: [Epoch 41, Loss1: 0.001218, Loss2: 0.001257]
Evaluation Set: [Epoch 41, Loss: 3.446869, Acc: 0.6918, AUC: 0.7373]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 195.41batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 205.63batches/s]
train model1: 100%|███████████████████████████████████████████| 12615/12615 [02:18<00:00, 91.23batches/s]
train model2: 100%|███████████████████████████████████████████| 12581/12581 [02:16<00:00, 92.18batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 86.28batches/s]
Training Set: [Epoch 42, Loss1: 1.742351, Loss2: 1.742527]
DivideMix Training: [Epoch 42, Loss1: 0.001217, Loss2: 0.001256]
Evaluation Set: [Epoch 42, Loss: 3.303297, Acc: 0.6915, AUC: 0.7294]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 195.63batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 203.83batches/s]
train model1: 100%|███████████████████████████████████████████| 12611/12611 [02:20<00:00, 90.02batches/s]
train model2: 100%|███████████████████████████████████████████| 12590/12590 [02:17<00:00, 91.41batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 86.97batches/s]
Training Set: [Epoch 43, Loss1: 1.696705, Loss2: 1.643793]
DivideMix Training: [Epoch 43, Loss1: 0.001216, Loss2: 0.001262]
Evaluation Set: [Epoch 43, Loss: 3.416463, Acc: 0.6915, AUC: 0.7334]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 196.26batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 205.98batches/s]
train model1: 100%|███████████████████████████████████████████| 12620/12620 [02:20<00:00, 89.75batches/s]
train model2: 100%|███████████████████████████████████████████| 12575/12575 [02:17<00:00, 91.21batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 85.96batches/s]
Training Set: [Epoch 44, Loss1: 1.736331, Loss2: 1.711528]
DivideMix Training: [Epoch 44, Loss1: 0.001221, Loss2: 0.001251]
Evaluation Set: [Epoch 44, Loss: 3.357100, Acc: 0.6913, AUC: 0.7314]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 196.44batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 203.82batches/s]
train model1: 100%|███████████████████████████████████████████| 12602/12602 [02:20<00:00, 89.45batches/s]
train model2: 100%|███████████████████████████████████████████| 12634/12634 [02:17<00:00, 92.21batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 89.11batches/s]
Training Set: [Epoch 45, Loss1: 1.707288, Loss2: 1.673887]
DivideMix Training: [Epoch 45, Loss1: 0.001208, Loss2: 0.001256]
Evaluation Set: [Epoch 45, Loss: 3.331771, Acc: 0.6916, AUC: 0.7270]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 200.37batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 210.58batches/s]
train model1: 100%|███████████████████████████████████████████| 12647/12647 [02:17<00:00, 92.27batches/s]
train model2: 100%|███████████████████████████████████████████| 12579/12579 [02:14<00:00, 93.64batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 89.31batches/s]
Training Set: [Epoch 46, Loss1: 1.725616, Loss2: 1.624473]
DivideMix Training: [Epoch 46, Loss1: 0.001219, Loss2: 0.001250]
Evaluation Set: [Epoch 46, Loss: 3.422273, Acc: 0.6913, AUC: 0.7376]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 201.28batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 209.23batches/s]
train model1: 100%|███████████████████████████████████████████| 12611/12611 [02:17<00:00, 91.62batches/s]
train model2: 100%|███████████████████████████████████████████| 12604/12604 [02:14<00:00, 93.74batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 89.21batches/s]
Training Set: [Epoch 47, Loss1: 1.723244, Loss2: 1.716572]
DivideMix Training: [Epoch 47, Loss1: 0.001212, Loss2: 0.001249]
Evaluation Set: [Epoch 47, Loss: 3.371383, Acc: 0.6916, AUC: 0.7322]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 201.39batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 210.31batches/s]
train model1: 100%|███████████████████████████████████████████| 12673/12673 [02:18<00:00, 91.38batches/s]
train model2: 100%|███████████████████████████████████████████| 12596/12596 [02:14<00:00, 93.70batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 88.79batches/s]
Training Set: [Epoch 48, Loss1: 1.700972, Loss2: 1.685622]
DivideMix Training: [Epoch 48, Loss1: 0.001221, Loss2: 0.001249]
Evaluation Set: [Epoch 48, Loss: 3.382716, Acc: 0.6915, AUC: 0.7358]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 200.08batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 208.63batches/s]
train model1: 100%|███████████████████████████████████████████| 12625/12625 [02:17<00:00, 91.52batches/s]
train model2: 100%|███████████████████████████████████████████| 12617/12617 [02:14<00:00, 93.46batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 88.87batches/s]
Training Set: [Epoch 49, Loss1: 1.661309, Loss2: 1.734893]
DivideMix Training: [Epoch 49, Loss1: 0.001210, Loss2: 0.001248]
Evaluation Set: [Epoch 49, Loss: 3.313598, Acc: 0.6915, AUC: 0.7337]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 201.83batches/s]
GMM processing: 100%|██████████████████████████████████████████| 1118/1118 [00:05<00:00, 210.24batches/s]
train model1: 100%|███████████████████████████████████████████| 12614/12614 [02:17<00:00, 91.62batches/s]
train model2: 100%|███████████████████████████████████████████| 12645/12645 [02:14<00:00, 94.34batches/s]
evaluate: 100%|███████████████████████████████████████████████████| 140/140 [00:01<00:00, 89.79batches/s]
Training Set: [Epoch 50, Loss1: 1.661618, Loss2: 1.663846]
DivideMix Training: [Epoch 50, Loss1: 0.001206, Loss2: 0.001256]
Evaluation Set: [Epoch 50, Loss: 3.411925, Acc: 0.6922, AUC: 0.7321]
Finished Training.
Training took 205.487351389726 minute.
