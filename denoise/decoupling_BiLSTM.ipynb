{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# decoupling\n",
    "# https://proceedings.neurips.cc/paper/2017/file/58d4d1e7b1e97b258c9ed0b37e02d087-Paper.pdf"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Iq4YfuLbcKgh"
   },
   "id": "Iq4YfuLbcKgh"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qj65Ip_Ae4_A",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5b7be18c-9dad-42ca-8e79-2576de9fbc48"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "id": "qj65Ip_Ae4_A"
  },
  {
   "cell_type": "code",
   "source": [
    "cd /content/drive/MyDrive"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LpRwnAnWcLaD",
    "outputId": "1141157e-cafb-4a43-de6d-38bc1c40a759"
   },
   "id": "LpRwnAnWcLaD",
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/drive/MyDrive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "ls"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26Lxf-iDcL17",
    "outputId": "d2b8cdb5-008f-41ba-b7db-4315117d0c16"
   },
   "id": "26Lxf-iDcL17",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "coteaching_BiLSTM.ipynb  \u001B[0m\u001B[01;34mdata\u001B[0m/  \u001B[01;34mparams\u001B[0m/  \u001B[01;34m__pycache__\u001B[0m/  week10ma.ipynb\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ded39806-fc83-4b0c-b9ce-14e896a4675f",
   "metadata": {
    "id": "ded39806-fc83-4b0c-b9ce-14e896a4675f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bbbe232-2c39-49c6-9187-a80c6812d813",
   "metadata": {
    "id": "2bbbe232-2c39-49c6-9187-a80c6812d813"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e449b96d-6e11-4b72-a5e6-8f20c1b71115",
   "metadata": {
    "id": "e449b96d-6e11-4b72-a5e6-8f20c1b71115"
   },
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    with open(path, 'r') as csvfile:\n",
    "        train_data = list(csv.reader(csvfile))[1:] # skip col name\n",
    "        sents, lbls = [], []\n",
    "        for s, l in train_data:\n",
    "            sents.append(s)\n",
    "            lbls.append(l)\n",
    "    return sents, lbls\n",
    "\n",
    "# number of trainable parameters in model\n",
    "def get_total_model_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9ffe646-fe1e-4c17-b3e5-c36ed03e81a8",
   "metadata": {
    "id": "e9ffe646-fe1e-4c17-b3e5-c36ed03e81a8"
   },
   "outputs": [],
   "source": [
    "class CleavageDataset(Dataset):\n",
    "    def __init__(self, seq, lbl):\n",
    "        self.seq = seq\n",
    "        self.lbl = lbl\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.seq[idx], self.lbl[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lbl)\n",
    "    \n",
    "class CleavageBatch:\n",
    "    def __init__(self, batch: List[Tuple[str, str]]):\n",
    "        ordered_batch = list(zip(*batch))\n",
    "        self.seq = torch.tensor([encode_text(seq) for seq in ordered_batch[0]], dtype=torch.int64)\n",
    "        self.lbl = torch.tensor([int(l) for l in ordered_batch[1]], dtype=torch.float)\n",
    "        \n",
    "    def pin_memory(self):\n",
    "        self.seq = self.seq.pin_memory()\n",
    "        self.lbl = self.lbl.pin_memory()\n",
    "        return self\n",
    "    \n",
    "def collate_wrapper(batch):\n",
    "    return CleavageBatch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4cc48e7-1186-4391-b9d8-924eee98b72c",
   "metadata": {
    "id": "b4cc48e7-1186-4391-b9d8-924eee98b72c"
   },
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_size, hidden_size, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=embedding_dim,\n",
    "        )\n",
    "        \n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=rnn_size,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(rnn_size * 2, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        # input shape: (batch_size, seq_len=10)\n",
    "        embedded = self.dropout(self.embedding(seq))\n",
    "        \n",
    "        # input shape: (batch_size, seq_len, embedding_dim)\n",
    "        out, _ = self.lstm(embedded)\n",
    "        \n",
    "        # input shape: (batch_size, seq_len, 2*hidden_size)\n",
    "        pooled = torch.mean(out, dim=1)\n",
    "        \n",
    "        # input shape: (batch_size, 2*hidden_size)\n",
    "        out = self.dropout(F.relu(self.fc1(pooled)))\n",
    "        \n",
    "        # input shape: (batch_size, hidden_size)\n",
    "        # output shape: (batch_size)\n",
    "        out = self.fc2(out).squeeze()\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "kaUEQh_bcKgk"
   },
   "id": "kaUEQh_bcKgk"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0e91040-ea43-4a0f-b17a-bcbb2b38ac99",
   "metadata": {
    "id": "a0e91040-ea43-4a0f-b17a-bcbb2b38ac99"
   },
   "outputs": [],
   "source": [
    "def train(model1, model2, loader, optim):\n",
    "    epoch_loss1, num_correct1, total = 0, 0, 0\n",
    "    epoch_loss2, num_correct2 = 0, 0\n",
    "    criterion = nn.BCEWithLogitsLoss(reduce=False)\n",
    "\n",
    "    for batch in tqdm(\n",
    "        loader,\n",
    "        desc=\"Train: \",\n",
    "        file=sys.stdout,\n",
    "        unit=\"batches\"\n",
    "    ):\n",
    "        seq, lbl = batch.seq, batch.lbl\n",
    "        seq, lbl = seq.to(device), lbl.to(device)\n",
    "        \n",
    "        scores1 = model1(seq)\n",
    "        #_, pred1 = torch.max(scores1)\n",
    "        pred1 = scores1 > 0\n",
    "\n",
    "        scores2 = model2(seq)\n",
    "        #_, pred2 = torch.max(scores2)\n",
    "        pred2 = scores2 > 0\n",
    "\n",
    "        inds = torch.where(pred1 != pred2)\n",
    "        loss1 = criterion(scores1[inds] , lbl[inds]).sum()\n",
    "        loss2 = criterion(scores2[inds] , lbl[inds]).sum()\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss1.backward()\n",
    "        loss2.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        epoch_loss1 += loss1.item()\n",
    "        epoch_loss2 += loss2.item()\n",
    "        num_correct1 += ((scores1 > 0) == lbl).sum()\n",
    "        num_correct2 += ((scores2 > 0) == lbl).sum()\n",
    "        total += len(seq)\n",
    "    return epoch_loss1 / total, epoch_loss2 / total, num_correct1 / total, num_correct2 / total"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate(model1, model2, loader):\n",
    "    epoch_loss1, num_correct1, total = 0, 0, 0\n",
    "    epoch_loss2, num_correct2 = 0, 0\n",
    "\n",
    "\n",
    "    for batch in tqdm(\n",
    "        loader,\n",
    "        desc=\"Eval: \",\n",
    "        file=sys.stdout,\n",
    "        unit=\"batches\"\n",
    "    ):\n",
    "        seq, lbl = batch.seq, batch.lbl\n",
    "        seq, lbl = seq.to(device), lbl.to(device)\n",
    "        \n",
    "        scores1 = model1(seq)\n",
    "        #_, pred1 = torch.max(scores1)\n",
    "        pred1 = scores1 > 0\n",
    "\n",
    "        scores2 = model2(seq)\n",
    "        #_, pred2 = torch.max(scores2)\n",
    "        pred2 = scores2 > 0\n",
    "\n",
    "        inds = torch.where(pred1 != pred2)\n",
    "        loss1 = criterion(scores1[inds] , lbl[inds]).sum()\n",
    "        loss2 = criterion(scores2[inds] , lbl[inds]).sum()\n",
    "        \n",
    "        epoch_loss1 += loss1.item()\n",
    "        epoch_loss2 += loss2.item()\n",
    "        num_correct1 += ((scores1 > 0) == lbl).sum()\n",
    "        num_correct2 += ((scores2 > 0) == lbl).sum()\n",
    "        total += len(seq)\n",
    "    return epoch_loss1 / total, epoch_loss2 / total, num_correct1 / total, num_correct2 / total"
   ],
   "metadata": {
    "id": "bX1NaYuY3FPl"
   },
   "id": "bX1NaYuY3FPl",
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42148192-6ec1-4ffa-8f86-2662575167dd",
   "metadata": {
    "id": "42148192-6ec1-4ffa-8f86-2662575167dd"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# load train and dev data\n",
    "train_seqs, train_lbl = read_data('data/n_train.csv')\n",
    "dev_seqs, dev_lbl = read_data('data/n_val.csv')\n",
    "\n",
    "# create vocab from train seqs\n",
    "vocab = build_vocab_from_iterator(train_seqs, specials=['<UNK>'])\n",
    "vocab.set_default_index(vocab['<UNK>'])\n",
    "encode_text = lambda x: vocab(list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fff5c30b-2822-4871-8ab5-0ec37673f1f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fff5c30b-2822-4871-8ab5-0ec37673f1f8",
    "outputId": "ce3b6757-605e-412b-a5c3-7bc8349d63a2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total trainable model1 parameters: 2,648,373\n",
      "Total trainable model2 parameters: 2,648,373\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 512\n",
    "VOCAB_SIZE = len(vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "RNN_SIZE = 512\n",
    "HIDDEN_SIZE = 128\n",
    "DROPOUT = 0.5\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "\n",
    "\n",
    "model1 = BiLSTM(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    rnn_size=RNN_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    dropout=DROPOUT\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model1.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "model2 = BiLSTM(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    rnn_size=RNN_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    dropout=DROPOUT\n",
    ").to(device)\n",
    "\n",
    "optimizer2 = optim.Adam(model1.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# create train and dev loader\n",
    "train_data = CleavageDataset(train_seqs, train_lbl)\n",
    "train_loader = DataLoader(train_data, batch_size = BATCH_SIZE, shuffle=True, collate_fn=collate_wrapper, pin_memory=True, num_workers=10)\n",
    "\n",
    "dev_data = CleavageDataset(dev_seqs, dev_lbl)\n",
    "dev_loader = DataLoader(dev_data, batch_size = BATCH_SIZE, shuffle=True, collate_fn=collate_wrapper, pin_memory=True, num_workers=10)\n",
    "\n",
    "print(f\"Total trainable model1 parameters: {get_total_model_params(model1):,}\")\n",
    "print(f\"Total trainable model2 parameters: {get_total_model_params(model1):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fbe5697-c1a7-4f53-9826-9e91e80d0b18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3fbe5697-c1a7-4f53-9826-9e91e80d0b18",
    "outputId": "69625ba2-1166-4813-b849-b569efb4ab9f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting Training.\n",
      "Train: 100%|██████████| 2236/2236 [01:50<00:00, 20.31batches/s]\n",
      "Eval: 100%|██████████| 280/280 [00:05<00:00, 52.83batches/s]\n",
      "Model1 Training:   [Epoch  1, Loss:   0.1081, Acc: 0.5834]\n",
      "Model1 Evaluation: [Epoch  1, Loss:   0.0013, Acc: 0.5997]\n",
      "Model2 Training:   [Epoch  1, Loss:   0.1101, Acc: 0.5651]\n",
      "Model2 Evaluation: [Epoch  1, Loss:   0.0014, Acc: 0.5795]\n",
      "Train: 100%|██████████| 2236/2236 [01:51<00:00, 19.97batches/s]\n",
      "Eval: 100%|██████████| 280/280 [00:05<00:00, 52.20batches/s]\n",
      "Model1 Training:   [Epoch  2, Loss:   0.2104, Acc: 0.6198]\n",
      "Model1 Evaluation: [Epoch  2, Loss:   0.0013, Acc: 0.6740]\n",
      "Model2 Training:   [Epoch  2, Loss:   0.2189, Acc: 0.5649]\n",
      "Model2 Evaluation: [Epoch  2, Loss:   0.0014, Acc: 0.5795]\n",
      "Train: 100%|██████████| 2236/2236 [01:53<00:00, 19.73batches/s]\n",
      "Eval: 100%|██████████| 280/280 [00:05<00:00, 52.11batches/s]\n",
      "Model1 Training:   [Epoch  3, Loss:   0.2551, Acc: 0.6779]\n",
      "Model1 Evaluation: [Epoch  3, Loss:   0.0013, Acc: 0.6740]\n",
      "Model2 Training:   [Epoch  3, Loss:   0.2818, Acc: 0.5646]\n",
      "Model2 Evaluation: [Epoch  3, Loss:   0.0014, Acc: 0.5795]\n",
      "Train: 100%|██████████| 2236/2236 [01:53<00:00, 19.77batches/s]\n",
      "Eval: 100%|██████████| 280/280 [00:05<00:00, 52.73batches/s]\n",
      "Model1 Training:   [Epoch  4, Loss:   0.2572, Acc: 0.6836]\n",
      "Model1 Evaluation: [Epoch  4, Loss:   0.0012, Acc: 0.6906]\n",
      "Model2 Training:   [Epoch  4, Loss:   0.2872, Acc: 0.5652]\n",
      "Model2 Evaluation: [Epoch  4, Loss:   0.0014, Acc: 0.5795]\n",
      "Train: 100%|██████████| 2236/2236 [01:53<00:00, 19.74batches/s]\n",
      "Eval: 100%|██████████| 280/280 [00:05<00:00, 52.34batches/s]\n",
      "Model1 Training:   [Epoch  5, Loss:   0.2528, Acc: 0.6869]\n",
      "Model1 Evaluation: [Epoch  5, Loss:   0.0012, Acc: 0.6898]\n",
      "Model2 Training:   [Epoch  5, Loss:   0.2849, Acc: 0.5650]\n",
      "Model2 Evaluation: [Epoch  5, Loss:   0.0014, Acc: 0.5795]\n",
      "Train: 100%|██████████| 2236/2236 [01:53<00:00, 19.74batches/s]\n",
      "Eval: 100%|██████████| 280/280 [00:05<00:00, 52.16batches/s]\n",
      "Model1 Training:   [Epoch  6, Loss:   0.2524, Acc: 0.6890]\n",
      "Model1 Evaluation: [Epoch  6, Loss:   0.0012, Acc: 0.6920]\n",
      "Model2 Training:   [Epoch  6, Loss:   0.2857, Acc: 0.5650]\n",
      "Model2 Evaluation: [Epoch  6, Loss:   0.0014, Acc: 0.5795]\n",
      "Train: 100%|██████████| 2236/2236 [01:53<00:00, 19.74batches/s]\n",
      "Eval: 100%|██████████| 280/280 [00:05<00:00, 52.77batches/s]\n",
      "Model1 Training:   [Epoch  7, Loss:   0.2532, Acc: 0.6903]\n",
      "Model1 Evaluation: [Epoch  7, Loss:   0.0012, Acc: 0.6944]\n",
      "Model2 Training:   [Epoch  7, Loss:   0.2874, Acc: 0.5649]\n",
      "Model2 Evaluation: [Epoch  7, Loss:   0.0014, Acc: 0.5795]\n",
      "Train: 100%|██████████| 2236/2236 [01:53<00:00, 19.74batches/s]\n",
      "Eval: 100%|██████████| 280/280 [00:05<00:00, 52.19batches/s]\n",
      "Model1 Training:   [Epoch  8, Loss:   0.2535, Acc: 0.6913]\n",
      "Model1 Evaluation: [Epoch  8, Loss:   0.0012, Acc: 0.6933]\n",
      "Model2 Training:   [Epoch  8, Loss:   0.2882, Acc: 0.5653]\n",
      "Model2 Evaluation: [Epoch  8, Loss:   0.0014, Acc: 0.5795]\n",
      "Train: 100%|██████████| 2236/2236 [01:53<00:00, 19.72batches/s]\n",
      "Eval: 100%|██████████| 280/280 [00:05<00:00, 52.35batches/s]\n",
      "Model1 Training:   [Epoch  9, Loss:   0.2490, Acc: 0.6921]\n",
      "Model1 Evaluation: [Epoch  9, Loss:   0.0012, Acc: 0.6944]\n",
      "Model2 Training:   [Epoch  9, Loss:   0.2844, Acc: 0.5651]\n",
      "Model2 Evaluation: [Epoch  9, Loss:   0.0014, Acc: 0.5795]\n",
      "Train: 100%|██████████| 2236/2236 [01:53<00:00, 19.73batches/s]\n",
      "Eval: 100%|██████████| 280/280 [00:05<00:00, 52.13batches/s]\n",
      "Model1 Training:   [Epoch 10, Loss:   0.2527, Acc: 0.6932]\n",
      "Model1 Evaluation: [Epoch 10, Loss:   0.0012, Acc: 0.6944]\n",
      "Model2 Training:   [Epoch 10, Loss:   0.2885, Acc: 0.5651]\n",
      "Model2 Evaluation: [Epoch 10, Loss:   0.0014, Acc: 0.5795]\n",
      "Finished Training.\n",
      "Training took 19.725769567489625 minutes.\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "print(\"Starting Training.\")\n",
    "highest_val_acc1, highest_val_acc2 = 0,0\n",
    "train_losses1, train_accuracies1= [], []\n",
    "train_losses2, train_accuracies2= [], []\n",
    "val_losses1, val_accuracies1 = [], []\n",
    "val_losses2, val_accuracies2 = [], []\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    model1.train()\n",
    "    model2.train()\n",
    "    train_loss1, train_loss2, train_acc1, train_acc2 = train(model1, model2, train_loader, optimizer)\n",
    "    \n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss1, val_loss2, val_acc1, val_acc2 = evaluate(model1, model2, dev_loader)\n",
    "        \n",
    "    # save current acc, loss model1\n",
    "    train_losses1.append((epoch, train_loss1))\n",
    "    train_accuracies1.append((epoch, train_acc1))\n",
    "    val_losses1.append((epoch, val_loss1))\n",
    "    val_accuracies1.append((epoch, val_acc1))\n",
    "    \n",
    "    if val_acc1 > highest_val_acc1:\n",
    "        highest_val_acc1 = val_acc1\n",
    "        path = f\"params/model1_acc{val_acc1:.4f}_epoch{epoch}.pt\"\n",
    "        torch.save(model1.state_dict(), path)\n",
    "\n",
    "\n",
    "    print(f\"Model1 Training:   [Epoch {epoch:2d}, Loss: {train_loss1:8.4f}, Acc: {train_acc1:.4f}]\")\n",
    "    print(f\"Model1 Evaluation: [Epoch {epoch:2d}, Loss: {val_loss1:8.4f}, Acc: {val_acc1:.4f}]\")\n",
    "\n",
    "\n",
    "    # save current acc, loss model2\n",
    "    train_losses2.append((epoch, train_loss2))\n",
    "    train_accuracies2.append((epoch, train_acc2))\n",
    "    val_losses2.append((epoch, val_loss2))\n",
    "    val_accuracies2.append((epoch, val_acc2))\n",
    "\n",
    "    if val_acc2 > highest_val_acc2:\n",
    "        highest_val_acc2 = val_acc2\n",
    "        path = f\"params/model2_acc{val_acc2:.4f}_epoch{epoch}.pt\"\n",
    "        torch.save(model2.state_dict(), path)\n",
    "\n",
    "    print(f\"Model2 Training:   [Epoch {epoch:2d}, Loss: {train_loss2:8.4f}, Acc: {train_acc2:.4f}]\")\n",
    "    print(f\"Model2 Evaluation: [Epoch {epoch:2d}, Loss: {val_loss2:8.4f}, Acc: {val_acc2:.4f}]\")\n",
    "    \n",
    "print(\"Finished Training.\")\n",
    "train_time = (time() - start) / 60\n",
    "print(f\"Training took {train_time} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126fd50d-b4b5-4da7-a8e5-8ebeed450b22",
   "metadata": {
    "id": "126fd50d-b4b5-4da7-a8e5-8ebeed450b22"
   },
   "outputs": [],
   "source": [
    "# save training stats\n",
    "lsts = [train_losses, train_accuracies, val_losses, val_accuracies, train_time]\n",
    "names = [\n",
    "    \"train_losses\",\n",
    "    \"train_accuracies\",\n",
    "    \"val_losses\",\n",
    "    \"val_accuracies\",\n",
    "    \"train_time\",\n",
    "]\n",
    "to_save = dict()\n",
    "for name, lst in zip(names, lsts):\n",
    "    to_save[name] = lst\n",
    "\n",
    "with open(f\"../params/n_term/quadBiLSTM/metrics.pkl\", \"wb\") as f:\n",
    "    pickle.dump(to_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Finished Saving Details.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b9f839-ffcd-4d84-b060-80bb75be99e7",
   "metadata": {
    "id": "08b9f839-ffcd-4d84-b060-80bb75be99e7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "colab": {
   "provenance": []
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}